# LM Studio セットアップガイド

このガイドでは、LM Studioを使用して日本語に強いQwen30B-A3BとQwen32Bモデルをセットアップする方法を説明します。

## 目次

1. [LM Studioのインストール](#lm-studioのインストール)
2. [Qwen30B-A3Bモデルのダウンロードと設定](#qwen30b-a3bモデルのダウンロードと設定)
3. [Qwen32Bモデルのダウンロードと設定](#qwen32bモデルのダウンロードと設定)
4. [APIサーバーの起動](#apiサーバーの起動)
5. [アプリケーションとの連携](#アプリケーションとの連携)
6. [トラブルシューティング](#トラブルシューティング)

## LM Studioのインストール

1. [LM Studio公式サイト](https://lmstudio.ai/)からMacOS用のインストーラーをダウンロードします。
2. ダウンロードしたインストーラーを実行し、指示に従ってインストールを完了します。
3. インストール後、LM Studioを起動します。

## Qwen30B-A3Bモデルのダウンロードと設定

Qwen30B-A3Bは日本語に強い高性能モデルで、医療ドメインの理解に優れています。

1. LM Studioを起動し、「Browse Models」タブを選択します。
2. 検索ボックスに「Qwen30B-A3B」と入力します。
3. 以下のモデルを見つけてダウンロードします：
   - `Qwen/Qwen1.5-32B-Chat-GGUF` (Q4_K_M量子化版を推奨)

4. ダウンロードが完了したら、「My Models」タブでモデルを選択します。
5. 「Load」ボタンをクリックしてモデルをロードします。

## Qwen32Bモデルのダウンロードと設定

Qwen32Bは大規模言語理解に優れた日本語対応モデルです。

1. LM Studioを起動し、「Browse Models」タブを選択します。
2. 検索ボックスに「Qwen32B」と入力します。
3. 以下のモデルを見つけてダウンロードします：
   - `Qwen/Qwen2-32B-Instruct-GGUF` (Q4_K_M量子化版を推奨)

4. ダウンロードが完了したら、「My Models」タブでモデルを選択します。
5. 「Load」ボタンをクリックしてモデルをロードします。

## APIサーバーの起動

1. LM Studioの「My Models」タブでモデルがロードされていることを確認します。
2. 画面右上の「Local Server」ボタンをクリックします。
3. 「Start Server」ボタンをクリックしてAPIサーバーを起動します。
4. デフォルトでは、サーバーは `http://localhost:1234/v1` で起動します。

## アプリケーションとの連携

1. 難病・希少疾患支援団体検索アプリケーションを起動します。
2. 「LLM検索」タブを選択します。
3. プロバイダーとして「LM Studio」を選択します。
4. モデルとして「Qwen30B-A3B」または「Qwen32B」を選択します。
5. ベースURLとして `http://localhost:1234/v1` を確認します。
6. これで、アプリケーションがLM StudioのAPIを使用してLLM検索を実行できるようになります。

## トラブルシューティング

### APIサーバーに接続できない場合

1. LM Studioが起動していることを確認します。
2. 「Local Server」タブでサーバーが起動していることを確認します。
3. ファイアウォールがポート1234をブロックしていないことを確認します。
4. 別のアプリケーションがポート1234を使用していないことを確認します。

### モデルのロードに失敗する場合

1. MacBook M4 Maxの場合、少なくとも32GB以上のRAMが必要です。
2. Qwen32Bモデルの場合、128GB以上のRAMを推奨します。
3. ディスク容量が十分にあることを確認します（各モデルは約10-20GB必要です）。
4. 量子化レベルを下げてみてください（例：Q4_K_M → Q3_K_M）。

### 日本語の応答が不自然な場合

1. システムプロンプトに日本語での応答を明示的に指定してみてください。
2. 温度（Temperature）パラメータを0.3-0.7の範囲に設定してみてください。
3. Top-Pパラメータを0.9に設定してみてください。

## パフォーマンス最適化

MacBook M4 Maxでの最適なパフォーマンスを得るためのヒント：

1. **Metal GPU加速の有効化**：
   - LM Studioの設定で「Use Metal」オプションが有効になっていることを確認します。

2. **メモリ設定の最適化**：
   - 「Context Size」を適切に設定します（4096-8192が推奨）。
   - 「Batch Size」を適切に設定します（128-512が推奨）。

3. **バックグラウンドアプリの終了**：
   - 他のメモリを多く使用するアプリケーションを閉じます。

4. **冷却の確保**：
   - MacBookが適切に冷却されていることを確認します。
   - 長時間の使用時は外部冷却パッドの使用を検討してください。

## 推奨スペック

- **最小要件**：MacBook M1 Pro 32GB RAM
- **推奨**：MacBook M4 Max 128GB RAM
- **ストレージ**：少なくとも50GB以上の空き容量
- **OS**：macOS Sonoma 14.0以上

これらの手順に従うことで、LM StudioとQwen30B-A3B/Qwen32Bモデルを使用して、難病・希少疾患支援団体検索アプリケーションの検索精度を向上させることができます。
